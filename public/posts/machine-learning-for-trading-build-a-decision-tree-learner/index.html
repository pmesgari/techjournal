<!DOCTYPE html>
<html lang="en-us">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/font-awesome/webfonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="preload" href="/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> Machine Learning for Trading: Build a Decision Tree Learner | Techjournal</title>
  <link rel = 'canonical' href = '//localhost:1313/posts/machine-learning-for-trading-build-a-decision-tree-learner/'>
  <meta name="description" content="An Engineer&#39;s Path in the World of Infrastructure, Math and Computer Science">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <script src="/js/obsidian-callouts.js" defer></script>
  <meta property="og:url" content="//localhost:1313/posts/machine-learning-for-trading-build-a-decision-tree-learner/">
  <meta property="og:site_name" content="Techjournal">
  <meta property="og:title" content="Machine Learning for Trading: Build a Decision Tree Learner">
  <meta property="og:description" content="Introduction The focus of this article is building a decision tree learner and evaluate its performance in different settings and finally compare it with a linear regression learner. The main learning goals are:
Supervised Learning: Understanding what is supervised learning and how to train, query and evaluate its performance Decision Tree: Learning how to build a decision tree and use it in different configurations Supervised Learning Consider a series of predictor(here predictor just means inputs) measurements xi,i=1,2,…,Nxi​,i=1,2,…,N where for each predictor there is an associated response measurement yiyi​. From a statistical point of view the goal is to usually find a fit such that we can relate the predictors to the responses as accurately as possible. This is interesting because it allows to understand the relationships between the predictors and responses and also we can use such a fit to make predictions of future values for responses given historical predictor data. Such problems where there is a series of predictor measurements and an accompanying series of response measurements belong to the supervised learning problems category.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-01-11T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-01-11T00:00:00+00:00">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Machine Learning for Trading: Build a Decision Tree Learner">
  <meta name="twitter:description" content="Introduction The focus of this article is building a decision tree learner and evaluate its performance in different settings and finally compare it with a linear regression learner. The main learning goals are:
Supervised Learning: Understanding what is supervised learning and how to train, query and evaluate its performance Decision Tree: Learning how to build a decision tree and use it in different configurations Supervised Learning Consider a series of predictor(here predictor just means inputs) measurements xi,i=1,2,…,Nxi​,i=1,2,…,N where for each predictor there is an associated response measurement yiyi​. From a statistical point of view the goal is to usually find a fit such that we can relate the predictors to the responses as accurately as possible. This is interesting because it allows to understand the relationships between the predictors and responses and also we can use such a fit to make predictions of future values for responses given historical predictor data. Such problems where there is a series of predictor measurements and an accompanying series of response measurements belong to the supervised learning problems category.">

  
  
  
  <link rel="stylesheet" href="//localhost:1313/css/styles.bd3be846f9c8f08e34b3bfdb0414e55b49a4d301ea57cc9cf040d03a4a7cdd342a9f3229c8f2030e8478e8bdb1e4c093b2c85bbda378c35de052031a8019301a.css" integrity="sha512-vTvoRvnI8I40s7/bBBTlW0mk0wHqV8yc8EDQOkp83TQqnzIpyPIDDoR46L2x5MCTsshbvaN4w13gUgMagBkwGg=="> 

  
   <link rel="stylesheet" href="//localhost:1313/css/custom.css"> 
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="//localhost:1313/images/favicon.ico" />

  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;" aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">All posts</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" //localhost:1313/posts/machine-learning-for-trading-optimize-portfolio/" aria-label="Previous">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="//localhost:1313/posts/computer-networks-qa-cdns/" aria-label="Next">
            <i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i>
          </a>
        </li>
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#" aria-label="Share">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f" aria-label="Facebook">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&text=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Twitter">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&title=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Linkedin">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&is_video=false&description=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Pinterest">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner&body=Check out this article: %2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f" aria-label="Email">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&title=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Pocket">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&title=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="reddit">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&name=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner&description=%3ch2%20id%3d%22introduction%22%3eIntroduction%3c%2fh2%3e%0a%3cp%3eThe%20focus%20of%20this%20article%20is%20building%20a%20decision%20tree%20learner%20and%20evaluate%20its%20performance%20in%20different%20settings%20and%20finally%20compare%20it%20with%20a%20linear%20regression%20learner.%20The%20main%20learning%20goals%20are%3a%3c%2fp%3e%0a%3cul%3e%0a%3cli%3e%3cstrong%3eSupervised%20Learning%3a%3c%2fstrong%3e%c2%a0Understanding%20what%20is%20supervised%20learning%20and%20how%20to%20train%2c%20query%20and%20evaluate%20its%20performance%3c%2fli%3e%0a%3cli%3e%3cstrong%3eDecision%20Tree%3a%3c%2fstrong%3e%c2%a0Learning%20how%20to%20build%20a%20decision%20tree%20and%20use%20it%20in%20different%20configurations%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch2%20id%3d%22supervised-learning%22%3eSupervised%20Learning%3c%2fh2%3e%0a%3cp%3eConsider%20a%20series%20of%20predictor%28here%20predictor%20just%20means%20inputs%29%20measurements%c2%a0xi%2ci%3d1%2c2%2c%e2%80%a6%2cNxi%e2%80%8b%2ci%3d1%2c2%2c%e2%80%a6%2cN%c2%a0where%20for%20each%20predictor%20there%20is%20an%20associated%20response%20measurement%c2%a0yiyi%e2%80%8b.%20From%20a%20statistical%20point%20of%20view%20the%20goal%20is%20to%20usually%20find%20a%20fit%20such%20that%20we%20can%20relate%20the%20predictors%20to%20the%20responses%20as%20accurately%20as%20possible.%20This%20is%20interesting%20because%20it%20allows%20to%20understand%20the%20relationships%20between%20the%20predictors%20and%20responses%20and%20also%20we%20can%20use%20such%20a%20fit%20to%20make%20predictions%20of%20future%20values%20for%20responses%20given%20historical%20predictor%20data.%20Such%20problems%20where%20there%20is%20a%20series%20of%20predictor%20measurements%20and%20an%20accompanying%20series%20of%20response%20measurements%20belong%20to%20the%20supervised%20learning%20problems%20category.%3c%2fp%3e" aria-label="Tumblr">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&t=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Hacker News">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    
    <div id="toc">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#supervised-learning">Supervised Learning</a></li>
    <li><a href="#cart-algorithms">CART Algorithms</a></li>
    <li><a href="#decision-tree-learner">Decision Tree Learner</a></li>
  </ul>
</nav>
    </div>
    
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        Machine Learning for Trading: Build a Decision Tree Learner
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          <time datetime="2023-01-11 00:00:00 &#43;0000 UTC" itemprop="datePublished">2023-01-11</time>
          
        </div>
        
        
        
        
      </div>
    </header>

    
    <div class="content" itemprop="articleBody">
      <h2 id="introduction">Introduction</h2>
<p>The focus of this article is building a decision tree learner and evaluate its performance in different settings and finally compare it with a linear regression learner. The main learning goals are:</p>
<ul>
<li><strong>Supervised Learning:</strong> Understanding what is supervised learning and how to train, query and evaluate its performance</li>
<li><strong>Decision Tree:</strong> Learning how to build a decision tree and use it in different configurations</li>
</ul>
<h2 id="supervised-learning">Supervised Learning</h2>
<p>Consider a series of predictor(here predictor just means inputs) measurements xi,i=1,2,…,Nxi​,i=1,2,…,N where for each predictor there is an associated response measurement yiyi​. From a statistical point of view the goal is to usually find a fit such that we can relate the predictors to the responses as accurately as possible. This is interesting because it allows to understand the relationships between the predictors and responses and also we can use such a fit to make predictions of future values for responses given historical predictor data. Such problems where there is a series of predictor measurements and an accompanying series of response measurements belong to the supervised learning problems category.</p>
<p>The opposite of supervised learning problems are unsupervised learning where there is no associated series of response measurements for the predictors. This makes the learning problem more challenging as we are sort of working in blind. Another way to say this is that we do not have a response variable to supervise our analysis. This is where the terms supervised and unsupervised originate from.</p>
<h2 id="cart-algorithms">CART Algorithms</h2>
<p>Classification and Regression Trees (CARTs) algorithms are used in supervised machine learning to deduct information from large data sets for prediction purposes. In this article we will build a decision tree learner focused on regression analysis, meaning the data we will work with is numerical.</p>
<h2 id="decision-tree-learner">Decision Tree Learner</h2>
<p>Our main learner is the decision tree learner based on JR Quinlan algorithm. The pseudocode of the algorithm is shown below.</p>
<p><img src="https://techjournal.nl/wp-content/uploads/2022/10/image.png" alt=""></p>
<p>The algorithm build a decision tree in a recursive manner. In the actual implementation a hyperparameter called leaf size is also introduced which determines the aggregation threshold of the learner. The decision on what is the best feature to split on is made by computing the feature with the highest correlation coefficient.</p>
<p>We train our learner using financial stock market data. Our predictor measurements will be the adjusted closing price of different index funds and our goal is to provide a prediction for the MSCI Emerging Markets (EM) index. We will use 60% of the data set to train the learner and the other 40% is used to evaluate the predictions.</p>
<p>The implementation of our decision tree is given below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DTLearner</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Decision Tree Learner
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    This class can be instantiated to create a decision learner for numerical analysis (regression)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        leaf_size (int):    the leaf size hyperparameter, used to decide the threshold of leaf aggregation
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        verbose (bool):     toggle to allow printing to screen
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        An instance of the class with a tree built from the data, the instance can then be used to query predictions
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__init__</span>(self, leaf_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>leaf_size <span style="color:#f92672">=</span> leaf_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>verbose <span style="color:#f92672">=</span> verbose
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tree <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_evidence</span>(self, data_x, data_y):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Add training evidence
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        The method combines the separate data sets into one data set, this makes building the tree easier later.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Usually the shape of data_x is something like (r, c) and data_y is (r, ). We can combine this two data sets
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        if we concatenate along the axis for which the dimensions are not necessarily equal. But it is required to
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        first reshape data_y so that instead of a vector it becomes a 2-d array with a single column.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            data_x (nd numpy array):    a multidimensional numpy array holding the factor values
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            data_y  (1d numpy array):   a vector of labels (a.k.a. Y values)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            None, it just combines the data and invokes build_tree method
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate((data_x, data_y[:, <span style="color:#66d9ef">None</span>]), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tree <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>build_tree(data)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>verbose:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;tree shape: </span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>tree<span style="color:#f92672">.</span>shape<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            print(self<span style="color:#f92672">.</span>tree)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">find_best_feature</span>(self, data):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Find the best feature to split
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        It finds the best feature to split the rows using the correlation coefficient. We need to watch out
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        for the situation where the standard deviation of feature_x is zero, since this will result
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        in a division by zero in the calculation of the correlation coefficient and will cause a runtime error
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            data (nd numpy array):  the data set as an n-dimensional numpy array
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            The best feature to split the data on, the returned value is an integer representing the column index.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            If there is a situation where the correlation coefficient for multiple columns are the same, it will
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            deterministicly return the last column.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        best_feature <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        best_corr_coef <span style="color:#f92672">=</span> float(<span style="color:#e6db74">&#39;-inf&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> range(data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>            feature_x <span style="color:#f92672">=</span> data[:, col]
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># check std first, to prevent division by zero when numpy tries to</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># calculate the covariance matrix</span>
</span></span><span style="display:flex;"><span>            std <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>std(feature_x)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> std <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                c <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>corrcoef(feature_x, y<span style="color:#f92672">=</span>data[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                c <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> c <span style="color:#f92672">&gt;=</span> best_corr_coef:
</span></span><span style="display:flex;"><span>                best_corr_coef <span style="color:#f92672">=</span> c
</span></span><span style="display:flex;"><span>                best_feature <span style="color:#f92672">=</span> col
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> best_feature
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_tree</span>(self, data):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Builds the decision tree for numerical analysis based on the JR Quinlan algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            data (nd numpy array):  the full data set as an n-dimensional numpy array
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            The decision tree as a nd numpy array in a tabular format where each row is
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            [best_feature_idx, split_val, relative_left_tree_node_idx, relative_right_tree_node_idx]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            A leaf can be determined when a given row has its best_feature_idx set to numpy nan.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">&lt;=</span> self<span style="color:#f92672">.</span>leaf_size:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>atleast_2d([np<span style="color:#f92672">.</span>nan, np<span style="color:#f92672">.</span>mean(data[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]), np<span style="color:#f92672">.</span>nan, np<span style="color:#f92672">.</span>nan])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>all(data[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> data[<span style="color:#ae81ff">0</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>atleast_2d([np<span style="color:#f92672">.</span>nan, data[<span style="color:#ae81ff">0</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], np<span style="color:#f92672">.</span>nan, np<span style="color:#f92672">.</span>nan])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        best_feature_idx <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>find_best_feature(data)
</span></span><span style="display:flex;"><span>        split_val <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>median(data[:, best_feature_idx])
</span></span><span style="display:flex;"><span>        ys <span style="color:#f92672">=</span> data[:, best_feature_idx]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>all(ys <span style="color:#f92672">&lt;=</span> split_val) <span style="color:#f92672">or</span> np<span style="color:#f92672">.</span>all(ys <span style="color:#f92672">&gt;</span> split_val):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>atleast_2d([np<span style="color:#f92672">.</span>nan, np<span style="color:#f92672">.</span>mean(ys), np<span style="color:#f92672">.</span>nan, np<span style="color:#f92672">.</span>nan])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        true_rows <span style="color:#f92672">=</span> data[data[:, best_feature_idx] <span style="color:#f92672">&lt;=</span> split_val]
</span></span><span style="display:flex;"><span>        false_rows <span style="color:#f92672">=</span> data[data[:, best_feature_idx] <span style="color:#f92672">&gt;</span> split_val]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        left_tree <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>build_tree(true_rows)
</span></span><span style="display:flex;"><span>        right_tree <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>build_tree(false_rows)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        root <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>atleast_2d([best_feature_idx, split_val, <span style="color:#ae81ff">1</span>, left_tree<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>vstack((root, left_tree, right_tree))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict</span>(self, point, node<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Predict the label for a given point
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            point (1d numpy array): 1 dimensional numpy array where each entry is the value for a feature
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            node (int): the current decision node
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            A prediction for the label of a given point from the decision tree.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>isnan(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">0</span>]):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        feature <span style="color:#f92672">=</span> int(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>        split_val <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> point[feature] <span style="color:#f92672">&lt;=</span> split_val:
</span></span><span style="display:flex;"><span>            node <span style="color:#f92672">+=</span> int(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">2</span>])
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            node <span style="color:#f92672">+=</span> int(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>predict(point, node)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">query</span>(self, points):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Query the decision tree to get predictions for the given points
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            points (nd numpy array):    nd numpy array where each entry is the value for a feature
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            An 1d numpy array where each entry is the prediction for a given point
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        predictions <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>empty([len(points), ])
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> idx, point <span style="color:#f92672">in</span> enumerate(points):
</span></span><span style="display:flex;"><span>            predictions[idx] <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>predict(point)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> predictions
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">print_tree</span>(self, node<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, spacing<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Print the decision tree
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            node (int): current node in the tree
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            spacing (str):  current spacing
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            None, it will just print the tree to the console
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>isnan(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">0</span>]):
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>spacing<span style="color:#e6db74">}</span><span style="color:#e6db74"> Label: </span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">1</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>spacing<span style="color:#e6db74">}</span><span style="color:#e6db74"> &lt;= </span><span style="color:#e6db74">{</span>self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">1</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>spacing<span style="color:#e6db74">}</span><span style="color:#e6db74"> --&gt; True:&#39;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>print_tree(int(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">2</span>]) <span style="color:#f92672">+</span> node, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>spacing<span style="color:#e6db74">}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>spacing<span style="color:#e6db74">}</span><span style="color:#e6db74"> --&gt; False:&#39;</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>print_tree(int(self<span style="color:#f92672">.</span>tree[node, <span style="color:#ae81ff">3</span>]) <span style="color:#f92672">+</span> node, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>spacing<span style="color:#e6db74">}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div>
    </div>
  </article>

  
  






  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/posts">All posts</a></li>
         
          <li><a href="/about">About</a></li>
        
      </ul>
    </div>

    
    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#supervised-learning">Supervised Learning</a></li>
    <li><a href="#cart-algorithms">CART Algorithms</a></li>
    <li><a href="#decision-tree-learner">Decision Tree Learner</a></li>
  </ul>
</nav>
    </div>
    

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f" aria-label="Facebook">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&text=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Twitter">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&title=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Linkedin">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&is_video=false&description=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Pinterest">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner&body=Check out this article: %2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f" aria-label="Email">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&title=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Pocket">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&title=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="reddit">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&name=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner&description=%3ch2%20id%3d%22introduction%22%3eIntroduction%3c%2fh2%3e%0a%3cp%3eThe%20focus%20of%20this%20article%20is%20building%20a%20decision%20tree%20learner%20and%20evaluate%20its%20performance%20in%20different%20settings%20and%20finally%20compare%20it%20with%20a%20linear%20regression%20learner.%20The%20main%20learning%20goals%20are%3a%3c%2fp%3e%0a%3cul%3e%0a%3cli%3e%3cstrong%3eSupervised%20Learning%3a%3c%2fstrong%3e%c2%a0Understanding%20what%20is%20supervised%20learning%20and%20how%20to%20train%2c%20query%20and%20evaluate%20its%20performance%3c%2fli%3e%0a%3cli%3e%3cstrong%3eDecision%20Tree%3a%3c%2fstrong%3e%c2%a0Learning%20how%20to%20build%20a%20decision%20tree%20and%20use%20it%20in%20different%20configurations%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch2%20id%3d%22supervised-learning%22%3eSupervised%20Learning%3c%2fh2%3e%0a%3cp%3eConsider%20a%20series%20of%20predictor%28here%20predictor%20just%20means%20inputs%29%20measurements%c2%a0xi%2ci%3d1%2c2%2c%e2%80%a6%2cNxi%e2%80%8b%2ci%3d1%2c2%2c%e2%80%a6%2cN%c2%a0where%20for%20each%20predictor%20there%20is%20an%20associated%20response%20measurement%c2%a0yiyi%e2%80%8b.%20From%20a%20statistical%20point%20of%20view%20the%20goal%20is%20to%20usually%20find%20a%20fit%20such%20that%20we%20can%20relate%20the%20predictors%20to%20the%20responses%20as%20accurately%20as%20possible.%20This%20is%20interesting%20because%20it%20allows%20to%20understand%20the%20relationships%20between%20the%20predictors%20and%20responses%20and%20also%20we%20can%20use%20such%20a%20fit%20to%20make%20predictions%20of%20future%20values%20for%20responses%20given%20historical%20predictor%20data.%20Such%20problems%20where%20there%20is%20a%20series%20of%20predictor%20measurements%20and%20an%20accompanying%20series%20of%20response%20measurements%20belong%20to%20the%20supervised%20learning%20problems%20category.%3c%2fp%3e" aria-label="Tumblr">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=%2f%2flocalhost%3a1313%2fposts%2fmachine-learning-for-trading-build-a-decision-tree-learner%2f&t=Machine%20Learning%20for%20Trading%3a%20Build%20a%20Decision%20Tree%20Learner" aria-label="Hacker News">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu-toggle" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;" aria-label="Menu">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
        <a id="toc-toggle" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;" aria-label="TOC">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share-toggle" class="icon" href="#" onclick="$('#share-footer').toggle();return false;" aria-label="Share">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" aria-label="Top of Page">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2025  Techjournal 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/posts">All posts</a></li>
         
        <li><a href="/about">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>


  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>

<script src=/js/code-copy.js></script>



  


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

</html>
